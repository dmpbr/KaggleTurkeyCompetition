{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data in\n",
    "df = pd.read_json('../dataset/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "3                            520          1                              510   \n",
       "4                             10          0                                0   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  \n",
       "3  luG3RmUAxxM  \n",
       "4  PIm3cjxTpOk  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings range: 0 to 255\n",
      "Encodings: {0: 126642, 1: 2133, 2: 2257, 3: 2306, 4: 2306, 5: 2386, 6: 2415, 7: 2393, 8: 2656, 9: 2591, 10: 2622, 11: 2724, 12: 2712, 13: 2789, 14: 2832, 15: 2931, 16: 2923, 17: 3044, 18: 3047, 19: 3116, 20: 3097, 21: 3161, 22: 3119, 23: 3209, 24: 3163, 25: 3364, 26: 3246, 27: 3213, 28: 3387, 29: 3271, 30: 3310, 31: 3354, 32: 3395, 33: 3523, 34: 3581, 35: 3632, 36: 3596, 37: 3636, 38: 3798, 39: 3723, 40: 3849, 41: 3831, 42: 3835, 43: 3962, 44: 3998, 45: 3921, 46: 4154, 47: 4151, 48: 4349, 49: 4220, 50: 4428, 51: 4447, 52: 4407, 53: 4487, 54: 4573, 55: 4749, 56: 4569, 57: 4627, 58: 4776, 59: 4874, 60: 4826, 61: 4997, 62: 4855, 63: 5074, 64: 5036, 65: 5095, 66: 5111, 67: 5358, 68: 5267, 69: 5526, 70: 5433, 71: 5492, 72: 5438, 73: 5436, 74: 5538, 75: 5501, 76: 5620, 77: 5782, 78: 5860, 79: 5738, 80: 5932, 81: 5783, 82: 6007, 83: 6180, 84: 6080, 85: 6126, 86: 6145, 87: 6085, 88: 6010, 89: 6150, 90: 6272, 91: 6253, 92: 6402, 93: 6449, 94: 6216, 95: 6320, 96: 6463, 97: 6364, 98: 6417, 99: 6535, 100: 6606, 101: 6708, 102: 6678, 103: 6572, 104: 6507, 105: 6626, 106: 6762, 107: 6547, 108: 6611, 109: 6632, 110: 6691, 111: 6662, 112: 6761, 113: 6777, 114: 6777, 115: 6773, 116: 6828, 117: 6723, 118: 6666, 119: 6684, 120: 6905, 121: 6868, 122: 6906, 123: 6761, 124: 6650, 125: 6672, 126: 6847, 127: 6697, 128: 6630, 129: 6813, 130: 6987, 131: 6618, 132: 6743, 133: 6643, 134: 6700, 135: 6684, 136: 6840, 137: 6458, 138: 6596, 139: 6655, 140: 6537, 141: 6549, 142: 6422, 143: 6433, 144: 6561, 145: 6599, 146: 6646, 147: 6563, 148: 6661, 149: 6496, 150: 6629, 151: 6664, 152: 6685, 153: 6541, 154: 6688, 155: 6600, 156: 6511, 157: 6401, 158: 6428, 159: 6356, 160: 6267, 161: 6452, 162: 6488, 163: 6168, 164: 6223, 165: 6188, 166: 6121, 167: 6214, 168: 6244, 169: 6025, 170: 5937, 171: 6079, 172: 5971, 173: 5742, 174: 5897, 175: 5776, 176: 5650, 177: 5538, 178: 5503, 179: 5484, 180: 5341, 181: 5516, 182: 5366, 183: 5381, 184: 5467, 185: 5175, 186: 5162, 187: 5119, 188: 5072, 189: 4974, 190: 5022, 191: 4874, 192: 4806, 193: 4930, 194: 4844, 195: 4708, 196: 4763, 197: 4593, 198: 4633, 199: 4670, 200: 4603, 201: 4428, 202: 4497, 203: 4431, 204: 4317, 205: 4241, 206: 4270, 207: 4278, 208: 4274, 209: 4009, 210: 4032, 211: 3984, 212: 4009, 213: 3877, 214: 3900, 215: 3785, 216: 3968, 217: 3738, 218: 3780, 219: 3540, 220: 3696, 221: 3631, 222: 3576, 223: 3407, 224: 3416, 225: 3506, 226: 3359, 227: 3291, 228: 3292, 229: 3134, 230: 3106, 231: 3055, 232: 3054, 233: 3081, 234: 2997, 235: 2984, 236: 2918, 237: 2809, 238: 2856, 239: 2735, 240: 2682, 241: 2614, 242: 2635, 243: 2582, 244: 2605, 245: 2572, 246: 2458, 247: 2451, 248: 2446, 249: 2393, 250: 2314, 251: 2352, 252: 2261, 253: 2243, 254: 2240, 255: 145449}\n",
      "Encoding samples range: 2 to 10\n",
      "Encoding samples: {2: 5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 1, 8: 3, 9: 56, 10: 1120}\n"
     ]
    }
   ],
   "source": [
    "#Examine the audio embedding data\n",
    "dist_encodings = {}\n",
    "dist_samples = {}\n",
    "for enc_array in df['audio_embedding']:\n",
    "    if len(enc_array) in dist_samples.keys():\n",
    "        dist_samples[len(enc_array)]+=1\n",
    "    else:\n",
    "        dist_samples[len(enc_array)]=1\n",
    "    for enc in enc_array:\n",
    "        for v in enc:\n",
    "            if v in dist_encodings.keys():\n",
    "                dist_encodings[v]+=1\n",
    "            else:\n",
    "                dist_encodings[v]=1\n",
    "\n",
    "print(\"Encodings range: {} to {}\".format(min(dist_encodings.keys()), max(dist_encodings.keys())))\n",
    "print(\"Encodings: {}\".format(dist_encodings))\n",
    "\n",
    "print(\"Encoding samples range: {} to {}\".format(min(dist_samples.keys()), max(dist_samples.keys())))\n",
    "print(\"Encoding samples: {}\".format(dist_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain: (1075, 10, 128); ytrain:(1075, 2), xval: (120, 10, 128); yval: (120, 2)\n",
      "[0 1 0 0 1 0 1 1 0 0]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and validation\n",
    "x_train_data, x_val_data = train_test_split(df,test_size=0.1,train_size=None,random_state=34,shuffle=True)\n",
    "\n",
    "def normalise_and_pad(sequence, max_val=255.0, max_seq_len=10):\n",
    "    ret = np.pad(np.array(sequence) / max_val, ((0, max_seq_len-len(sequence)),(0,0)), 'wrap')\n",
    "    return ret\n",
    "\n",
    "\n",
    "def create_binary_classifier(binary_array):\n",
    "    yvals = np.zeros(shape=(len(binary_array), 2), dtype='float32')\n",
    "    for idx, val in enumerate(binary_array):\n",
    "        if val == 1:\n",
    "            yvals[idx][1] = 1\n",
    "        else:\n",
    "            yvals[idx][0] = 1\n",
    "    return yvals\n",
    "    \n",
    "    \n",
    "\n",
    "xtrain = np.asarray([normalise_and_pad(x) for x in x_train_data['audio_embedding']], dtype='float32')\n",
    "ytrain = create_binary_classifier(x_train_data['is_turkey'].values)\n",
    "\n",
    "\n",
    "xval = np.asarray([normalise_and_pad(x) for x in x_val_data['audio_embedding']], dtype='float32')\n",
    "yval = create_binary_classifier(x_val_data['is_turkey'].values)\n",
    "\n",
    "#Examine types and compare outputs\n",
    "print(\"xtrain: {}; ytrain:{}, xval: {}; yval: {}\".format(xtrain.shape, ytrain.shape, xval.shape, yval.shape))\n",
    "\n",
    "print(x_train_data['is_turkey'].values[:10])\n",
    "print(ytrain[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x_train, y_train, batch_size):\n",
    "    current_index=0\n",
    "    while current_index+batch_size < len(x_train):\n",
    "        batch_x = x_train[current_index:current_index+batch_size]\n",
    "        batch_y = y_train[current_index:current_index+batch_size]\n",
    "        yield (batch_x, batch_y)\n",
    "        current_index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#Set logging and reset the graph\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = '../model/model.ckpt'\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.000005\n",
    "training_epochs = 800\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 5\n",
    "keep_prob_val = 0.5\n",
    "\n",
    "n_input = 10*128  #10*128 audio embeddings\n",
    "n_classes = 2  # is not vs is turkey \n",
    "\n",
    "logdir = '../logs'\n",
    "\n",
    "#Size of the network:\n",
    "n_hidden_layer_1 = 512 # layer number of features\n",
    "n_hidden_layer_2 = 256 # layer number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"variables_scope\"):\n",
    "    \n",
    "    with tf.name_scope(\"input_variables\"):\n",
    "        # tf Graph input\n",
    "        x = tf.placeholder(\"float32\", [None, 10, 128], name=\"input_x\")\n",
    "        y = tf.placeholder(\"float32\", [None, n_classes], name=\"targets\")\n",
    "        keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "\n",
    "        x_flat = tf.reshape(x, [-1, n_input], name=\"input_x_flat\")\n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"weights_scope\"):\n",
    "        # Store layers weight & bias\n",
    "        weights = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_input, n_hidden_layer_1]), name=\"w_hidden_1\"),\n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer_1, n_hidden_layer_2]), name=\"w_hidden_2\"),\n",
    "            #'hidden_layer_3': tf.Variable(tf.random_normal([n_hidden_layer_2, n_hidden_layer_3]), name=\"w_hidden_3\"),\n",
    "            #'hidden_layer_4': tf.Variable(tf.random_normal([n_hidden_layer_3, n_hidden_layer_4]), name=\"w_hidden_4\"),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_layer_2, n_classes]), name=\"w_out\")\n",
    "        }\n",
    "        tf.summary.histogram(\"weight_histogram_hidden_1\", weights['hidden_layer_1'])\n",
    "        tf.summary.histogram(\"weight_histogram_hidden_2\", weights['hidden_layer_2'])\n",
    "        #tf.summary.histogram(\"weight_histogram_hidden_3\", weights['hidden_layer_3'])\n",
    "        #tf.summary.histogram(\"weight_histogram_hidden_4\", weights['hidden_layer_4'])\n",
    "        tf.summary.histogram(\"weight_histogram_out\", weights['out'])\n",
    "        \n",
    "        biases = {\n",
    "            'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer_1])),\n",
    "            'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer_2])),\n",
    "            #'hidden_layer_3': tf.Variable(tf.random_normal([n_hidden_layer_3])),\n",
    "            #'hidden_layer_4': tf.Variable(tf.random_normal([n_hidden_layer_4])),\n",
    "            'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "        }\n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"network_scope\"):\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer_1']),biases['hidden_layer_1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer_2']),biases['hidden_layer_2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "#         layer_3 = tf.add(tf.matmul(layer_2, weights['hidden_layer_3']),biases['hidden_layer_3'])\n",
    "#         layer_3 = tf.nn.relu(layer_3)\n",
    "#         layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "        \n",
    "#         layer_4 = tf.add(tf.matmul(layer_3, weights['hidden_layer_4']),biases['hidden_layer_4'])\n",
    "#         layer_4 = tf.nn.relu(layer_4)\n",
    "#         layer_4 = tf.nn.dropout(layer_4, keep_prob)\n",
    "\n",
    "        # Output layer with linear activation\n",
    "        logits = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "        tf.summary.histogram(\"logits_histogram\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"training_scope\"):\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y), name='cost')\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost, name='gradDescent')\n",
    "    tf.summary.histogram(\"loss_histogram\", cost)\n",
    "    tf.summary.scalar(\"loss_scalar\", cost)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "with tf.name_scope(\"accuracy_scope\"):\n",
    "    argmax_logits = tf.argmax(logits, 1)\n",
    "    argmax_y = tf.argmax(y, 1)\n",
    "    correct_prediction = tf.equal(argmax_logits, argmax_y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.histogram(\"accurace_scalar\", accuracy)\n",
    "    tf.summary.scalar(\"accurace_scalar\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.5916666388511658\n",
      "Epoch 5   - Validation Accuracy: 0.5916666388511658\n",
      "Epoch 10  - Validation Accuracy: 0.6083333492279053\n",
      "Epoch 15  - Validation Accuracy: 0.6083333492279053\n",
      "Epoch 20  - Validation Accuracy: 0.6000000238418579\n",
      "Epoch 25  - Validation Accuracy: 0.6166666746139526\n",
      "Epoch 30  - Validation Accuracy: 0.6416666507720947\n",
      "Epoch 35  - Validation Accuracy: 0.6583333611488342\n",
      "Epoch 40  - Validation Accuracy: 0.6583333611488342\n",
      "Epoch 45  - Validation Accuracy: 0.6666666865348816\n",
      "Epoch 50  - Validation Accuracy: 0.699999988079071\n",
      "Epoch 55  - Validation Accuracy: 0.7250000238418579\n",
      "Epoch 60  - Validation Accuracy: 0.7250000238418579\n",
      "Epoch 65  - Validation Accuracy: 0.7333333492279053\n",
      "Epoch 70  - Validation Accuracy: 0.7333333492279053\n",
      "Epoch 75  - Validation Accuracy: 0.7416666746139526\n",
      "Epoch 80  - Validation Accuracy: 0.7416666746139526\n",
      "Epoch 85  - Validation Accuracy: 0.7416666746139526\n",
      "Epoch 90  - Validation Accuracy: 0.7416666746139526\n",
      "Epoch 95  - Validation Accuracy: 0.7666666507720947\n",
      "Epoch 100 - Validation Accuracy: 0.7749999761581421\n",
      "Epoch 105 - Validation Accuracy: 0.7833333611488342\n",
      "Epoch 110 - Validation Accuracy: 0.7749999761581421\n",
      "Epoch 115 - Validation Accuracy: 0.7833333611488342\n",
      "Epoch 120 - Validation Accuracy: 0.7916666865348816\n",
      "Epoch 125 - Validation Accuracy: 0.7916666865348816\n",
      "Epoch 130 - Validation Accuracy: 0.800000011920929\n",
      "Epoch 135 - Validation Accuracy: 0.800000011920929\n",
      "Epoch 140 - Validation Accuracy: 0.8083333373069763\n",
      "Epoch 145 - Validation Accuracy: 0.8166666626930237\n",
      "Epoch 150 - Validation Accuracy: 0.824999988079071\n",
      "Epoch 155 - Validation Accuracy: 0.8333333134651184\n",
      "Epoch 160 - Validation Accuracy: 0.8333333134651184\n",
      "Epoch 165 - Validation Accuracy: 0.8333333134651184\n",
      "Epoch 170 - Validation Accuracy: 0.824999988079071\n",
      "Epoch 175 - Validation Accuracy: 0.8416666388511658\n",
      "Epoch 180 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 185 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 190 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 195 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 200 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 205 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 210 - Validation Accuracy: 0.8500000238418579\n",
      "Epoch 215 - Validation Accuracy: 0.8583333492279053\n",
      "Epoch 220 - Validation Accuracy: 0.8583333492279053\n",
      "Epoch 225 - Validation Accuracy: 0.8583333492279053\n",
      "Epoch 230 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 235 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 240 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 245 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 250 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 255 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 260 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 265 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 270 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 275 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 280 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 285 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 290 - Validation Accuracy: 0.8666666746139526\n",
      "Epoch 295 - Validation Accuracy: 0.875\n",
      "Epoch 300 - Validation Accuracy: 0.875\n",
      "Epoch 305 - Validation Accuracy: 0.875\n",
      "Epoch 310 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 315 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 320 - Validation Accuracy: 0.875\n",
      "Epoch 325 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 330 - Validation Accuracy: 0.875\n",
      "Epoch 335 - Validation Accuracy: 0.875\n",
      "Epoch 340 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 345 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 350 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 355 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 360 - Validation Accuracy: 0.8833333253860474\n",
      "Epoch 365 - Validation Accuracy: 0.8916666507720947\n",
      "Epoch 370 - Validation Accuracy: 0.8999999761581421\n",
      "Epoch 375 - Validation Accuracy: 0.8916666507720947\n",
      "Epoch 380 - Validation Accuracy: 0.8916666507720947\n",
      "Epoch 385 - Validation Accuracy: 0.8916666507720947\n",
      "Epoch 390 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 395 - Validation Accuracy: 0.8916666507720947\n",
      "Epoch 400 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 405 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 410 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 415 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 420 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 425 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 430 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 435 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 440 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 445 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 450 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 455 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 460 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 465 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 470 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 475 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 480 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 485 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 490 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 495 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 500 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 505 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 510 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 515 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 520 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 525 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 530 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 535 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 540 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 545 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 550 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 555 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 560 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 565 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 570 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 575 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 580 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 585 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 590 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 595 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 600 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 605 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 610 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 615 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 620 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 625 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 630 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 635 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 640 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 645 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 650 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 655 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 660 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 665 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 670 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 675 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 680 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 685 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 690 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 695 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 700 - Validation Accuracy: 0.9083333611488342\n",
      "Epoch 705 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 710 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 715 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 720 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 725 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 730 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 735 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 740 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 745 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 750 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 755 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 760 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 765 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 770 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 775 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 780 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 785 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 790 - Validation Accuracy: 0.9166666865348816\n",
      "Epoch 795 - Validation Accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# TensorBoard - Write the default graph out so we can view it's structure\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "tbWriter = tf.summary.FileWriter(logdir)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tbWriter.add_graph(sess.graph)\n",
    "    # Training cycle\n",
    "    step = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        for batch_x, batch_y in get_batches(xtrain, ytrain, batch_size):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: keep_prob_val})\n",
    "            \n",
    "            if step % 5 == 0:\n",
    "                summary = sess.run(merged_summary_op, feed_dict={x: batch_x, y: batch_y, keep_prob: keep_prob_val})\n",
    "                tbWriter.add_summary(summary, step)\n",
    "            \n",
    "            step+=1\n",
    "        \n",
    "        # Print status for every 10 epochs        \n",
    "        if epoch % display_step == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    x: xval,\n",
    "                    y: yval,\n",
    "                    keep_prob: 1.0})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "            \n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>THhP1idrWXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...   \n",
       "1  [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...   \n",
       "2  [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...   \n",
       "3  [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...   \n",
       "4  [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip       vid_id  \n",
       "0                             10                                0  pyKh38FXD3E  \n",
       "1                             40                               30  THhP1idrWXA  \n",
       "2                             40                               30  jsw3T6GY2Nw  \n",
       "3                             24                               14  nFkXTMHcjMU  \n",
       "4                             40                               30  Au8g9kAlrLQ  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the test data in\n",
    "df_test = pd.read_json('../dataset/test.json')\n",
    "print(len(df_test['vid_id']))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xsubmission: (1196, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "#Process the data to be ready to feed the model\n",
    "xsubmission = np.asarray([normalise_and_pad(x) for x in df_test['audio_embedding']], dtype='float32')\n",
    "\n",
    "#Examine types and compare outputs\n",
    "print(\"xsubmission: {}\".format(xsubmission.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 1196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_id</th>\n",
       "      <th>is_turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THhP1idrWXA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        vid_id  is_turkey\n",
       "0  pyKh38FXD3E          0\n",
       "1  THhP1idrWXA          0\n",
       "2  jsw3T6GY2Nw          0\n",
       "3  nFkXTMHcjMU          0\n",
       "4  Au8g9kAlrLQ          1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    argmax_output = sess.run(\n",
    "                argmax_logits,\n",
    "                feed_dict={\n",
    "                    x: xsubmission,\n",
    "                    y: yval,\n",
    "                    keep_prob: 1.0})\n",
    "\n",
    "\n",
    "submit_df = pd.DataFrame(columns=['vid_id', 'is_turkey'])\n",
    "submit_df['vid_id'] = df_test['vid_id']\n",
    "submit_df['is_turkey'] = list(argmax_output)\n",
    "print(\"Dataframe size: {}\".format(len(submit_df['vid_id'])))\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('../results/submission_turkey.csv',index=None,columns=['vid_id','is_turkey'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
